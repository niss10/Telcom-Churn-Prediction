{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95925ba",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a10a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./Telco_Customer_Churn.csv')\n",
    "\n",
    "# Display first few rows and check data types\n",
    "print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5d736",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handling missing or incorrect values\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
    "\n",
    "# Visualize distributions of numerical features\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histograms for tenure and MonthlyCharges\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['tenure'], bins=20, edgecolor='k')\n",
    "plt.title('Distribution of Tenure')\n",
    "plt.xlabel('Tenure (Months)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df['MonthlyCharges'], bins=20, edgecolor='k')\n",
    "plt.title('Distribution of Monthly Charges')\n",
    "plt.xlabel('Monthly Charges')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee924a9",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae0e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Drop 'customerID' and separate target\n",
    "df_clean = df.drop('customerID', axis=1)\n",
    "X = df_clean.drop('Churn', axis=1)\n",
    "y = df_clean['Churn'].map({'Yes': 1, 'No': 0})  # Encode target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24663fab",
   "metadata": {},
   "source": [
    "# 4. Baseline Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "# Logistic regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_preprocessed, y_train)\n",
    "y_pred = model.predict(X_test_preprocessed)\n",
    "y_pred_prob = model.predict_proba(X_test_preprocessed)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_pred_prob))\n",
    "print(\"\n",
    "Classification Report:\n",
    "\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140ad60a",
   "metadata": {},
   "source": [
    "# 5. Advanced Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dc97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train_preprocessed, y_train)\n",
    "    y_pred = clf.predict(X_test_preprocessed)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\n",
    "\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d240bb40",
   "metadata": {},
   "source": [
    "# 6. Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ec8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# SMOTE for class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "print(\"Class distribution after SMOTE:\", pd.Series(y_train_balanced).value_counts())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
